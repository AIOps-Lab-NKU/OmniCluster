[preprocess]
; 是否移除极值 true or false
if_remove_extreme = True
; 移除top `extreme_per`%极值0.01-0.1
extreme_per = 0.05
;去除极值的方式 extreme or deviation-mean
remove_extreme_mode = deviation-mean
; 是否对数据进行平滑处理 true or false
if_moving_average = True
; 平滑处理窗口大小 2,6,12,24,36,72
moving_window_size = 12
; 窗口的最小观测值
min_periods = 1
; 是否进行数据归一化/标准化 true or false
if_feature_scaling = True
; norm:归一化 stand：标准化 norm or stand
mode = norm

[train_ae]
; 使用的一维卷积层数 3,4,5
layers_num = 3
; 每层使用的kernel_size 3,5,7
kernel_size_list = [7, 7, 7]
; 每层使用的stride 2,3
stride_list = [2, 2, 2]
; 每层使用的output_padding
output_padding_list = [1, 0, 1]
; 每层使用的filters 16,32,64
filters_list = [32, 64, 1]
; dropout比例
dropout_list = [0, 0, 0]
; 激活函数 你好像换了一个，哪个好直接用就行了，不用调
activation = sigmoid
; 使用的batch_size大小
batch_size = 256
; 训练轮数
epochs = 100
; 验证集比例
validation_split = 0.1

; yin不用仔细调整
[yin]
; 每个周期最少包含`win_min`个点 可以调大一点 减少计算yin的开销，不影响效果即可
win_min = 35
; 每个周期最多包含`win_max`个点
win_max = 40
; 低于阈值则认为周期性成立
th = 0.1

;这周期性代码修改为不筛选具体周期性，只根据是否具有周期性进行筛选，根据你算出来的矩阵调整一下比例即可
[feature_selection]
; 指标周期性阈值，该指标具有周期性的数据数量大于`index_th`时认为该指标为有效指标，目前使用`0.2*数据数量`得到
index_th = 953
; 指标相似度阈值，两个指标相似度大于`sim_th`时认为两个指标具有相似度
sim_th = 0.95
; 指标相似度阈值，两个指标具有相似度的数据数量大于`sim_num_th`时认为可以去除冗余，目前使用`0.5*数据数量`得到
sim_num_th = 2857

[cal_dis]
; 可以计算的距离度量方式 ["Euclidean", "PearsonDistance", "NormEuclidean", "Square", "Manhattan", "SBD"]
dis_list = ["Euclidean"]
; 计算得到的距离矩阵保存路径
distance_dir = new-data/distance-all

; 聚类方式分别使用层次聚类和DBSCAN
[cluster]
; 可以计算的距离度量方式 ["Euclidean", "PearsonDistance", "NormEuclidean", "Square", "Manhattan", "SBD"]
dis_list = ["Euclidean"]
; https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering
; complete, average, single
linkage = average
; 两条数据间距离大于该值时不能被合并，暂时随便写了一个数 3-8试一下
distance_threshold = 10
label_file = new-data/label.npy
